{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1LmPGtaNEo52ULbhGA2RiHU9N_34D3i9Z","authorship_tag":"ABX9TyP0DbmUJrZiyZazJCYQaa8W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1Z1KIC3m6Slc"},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch.utils import data\n","import d2l"]},{"cell_type":"code","source":["true_w = torch.tensor([2, -3.4])\n","true_b = 4.2\n","features, labels = d2l.synthetic_data(true_w, true_b, 1000)"],"metadata":{"id":"UdXKkr1a6lp5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 10\n","data_iter = d2l.load_array((features, labels), batch_size)"],"metadata":{"id":"Qhs1rEUO66_S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["next(iter(data_iter))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"whvykpOj80qk","executionInfo":{"status":"ok","timestamp":1756826988453,"user_tz":-480,"elapsed":32,"user":{"displayName":"xun zhu","userId":"10805151323215125307"}},"outputId":"d00cf165-a0e2-49e2-fa83-60816cf8fc46"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[-1.4042, -0.0725],\n","         [-0.5553,  2.0313],\n","         [ 1.6335,  0.0525],\n","         [ 0.1892,  0.3992],\n","         [ 1.1484, -0.3661],\n","         [ 1.6306, -0.0947],\n","         [ 0.6560, -0.8507],\n","         [-1.1975, -1.1358],\n","         [ 0.6733,  1.0702],\n","         [ 0.5960, -1.2576]]),\n"," tensor([[ 1.6372],\n","         [-3.8125],\n","         [ 7.2663],\n","         [ 3.2248],\n","         [ 7.7368],\n","         [ 7.7888],\n","         [ 8.4078],\n","         [ 5.6583],\n","         [ 1.9217],\n","         [ 9.6692]])]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#对于标准深度学习模型，我们可以使用框架的预定义好的层。\n","#这使我们只需关注使用哪些层来构造模型，而不必关注层的实现细节。\n","#我们首先定义一个模型变量net，它是一个Sequential类的实例。\n","#Sequential类将多个层串联在一起。 当给定输入数据时，\n","#Sequential实例将数据传入到第一层， 然后将第一层的输出作为第二层的输入，以此类推。 在下面的例子中，我们的模型只包含一个层，因此实际上不需要Sequential。\n","#但是由于以后几乎所有的模型都是多层的，在这里使用Sequential会让你熟悉“标准的流水线”。\n","\n","# nn是神经网络的缩写\n","from torch import nn\n","\n","net = nn.Sequential(nn.Linear(2, 1))"],"metadata":{"id":"bS7qkcvR9GW0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#在使用net之前，我们需要初始化模型参数。 如在线性回归模型中的权重和偏置。 深度学习框架通常有预定义的方法来初始化参数。\n","#在这里，我们指定每个权重参数应该从均值为0、标准差为0.01的正态分布中随机采样， 偏置参数将初始化为零。\n","net[0].weight.data.normal_(0, 0.01)\n","net[0].bias.data.fill_(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UfAnpcU0-YPw","executionInfo":{"status":"ok","timestamp":1756826988548,"user_tz":-480,"elapsed":7,"user":{"displayName":"xun zhu","userId":"10805151323215125307"}},"outputId":"4f4327f1-1bb1-4ef2-bd30-16d6c42fcc98"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# 定义损失函数\n","loss = nn.MSELoss()"],"metadata":{"id":"ys0aNaXKBkBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 定义优化算法\n","trainer = torch.optim.SGD(net.parameters(), lr=0.03)"],"metadata":{"id":"L6PH1A8kBvAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#训练\n","num_epochs = 3\n","for epoch in range(num_epochs):\n","    for X, y in data_iter:\n","        l = loss(net(X) ,y)\n","        trainer.zero_grad()\n","        l.backward()\n","        trainer.step()\n","    l = loss(net(features), labels)\n","    print(f'epoch {epoch + 1}, loss {l:f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPla9qcnB5T5","executionInfo":{"status":"ok","timestamp":1756826994543,"user_tz":-480,"elapsed":375,"user":{"displayName":"xun zhu","userId":"10805151323215125307"}},"outputId":"e34b0779-e628-45ac-f54e-d14c05ffe94b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1, loss 0.000325\n","epoch 2, loss 0.000099\n","epoch 3, loss 0.000100\n"]}]},{"cell_type":"code","source":["w = net[0].weight.data\n","print('w的估计误差：', true_w - w.reshape(true_w.shape))\n","b = net[0].bias.data\n","print('b的估计误差：', true_b - b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4P3FTKYOCEBE","executionInfo":{"status":"ok","timestamp":1756826994556,"user_tz":-480,"elapsed":10,"user":{"displayName":"xun zhu","userId":"10805151323215125307"}},"outputId":"7b631335-a0dd-4b04-de26-5235ce82ca5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["w的估计误差： tensor([-0.0011,  0.0003])\n","b的估计误差： tensor([0.0007])\n"]}]}]}